{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae78a598",
   "metadata": {},
   "source": [
    "## Cross enthropy class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41a5cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3edc2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    \n",
    "    def __init__(self,api_config):\n",
    "        self.best = [] # {value:eval,vars:{}}\n",
    "        self.parser = Parser(api_config)\n",
    "        mean , var = self.parser.initial_mean_and_variance()\n",
    "        self.mean = np.array(mean)\n",
    "        self.var_covar = np.array(var)\n",
    "    \n",
    "    def observe(self,X,y):\n",
    "        for xx, yy in zip(X, y):\n",
    "            self.best.append({\"value\":yy,\"indiv\":xx})\n",
    "        self.best = sorted(self.best,key=lambda x:x[\"value\"])\n",
    "        self.best = self.best[0:15]\n",
    "        \n",
    "        if(len(self.best)<4):\n",
    "            # dont update with less than 4 elements \n",
    "            return \n",
    "        \n",
    "        #new matrixn\n",
    "        vectors = [self.parser.convert_for_inside(self.best[0][\"indiv\"])]\n",
    "        new_mean = self.parser.convert_for_inside(self.best[0][\"indiv\"])\n",
    "        for i in range(1,len(self.best)):\n",
    "            tmp = self.parser.convert_for_inside(self.best[i][\"indiv\"])\n",
    "            vectors.append(tmp)\n",
    "            new_mean = new_mean + tmp\n",
    "        new_mean = new_mean / len(self.best)\n",
    "        \n",
    "        new_var = np.zeros((len(new_mean),len(new_mean)))\n",
    "        \n",
    "        for v in vectors:\n",
    "            new_var = new_var + v[np.newaxis].T.dot(v[np.newaxis])\n",
    "        new_var = new_var / len(self.best)\n",
    "        \n",
    "        self.mean = new_mean\n",
    "        self.var_covar = new_var\n",
    "        \n",
    "        \n",
    "    \n",
    "    def suggest(self,n_suggest=1):\n",
    "        result = []\n",
    "        for i in range(0,n_suggest):\n",
    "            result.append(self.parser.convert_for_outside(np.random.multivariate_normal(self.mean,self.var_covar)))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf0fde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self,api_config):\n",
    "        self.keys = []\n",
    "        self.interpretors = []\n",
    "        #type_v is one of 'real', 'int', 'cat', 'bool'\n",
    "        for variables in api_config.keys():\n",
    "            self.keys.append(variables)\n",
    "        \n",
    "        for param_name in self.keys:\n",
    "            param_config = api_config[param_name]\n",
    "\n",
    "            param_type = param_config[\"type\"]\n",
    "            param_space = param_config.get(\"space\", None)\n",
    "            param_range = param_config.get(\"range\", None)\n",
    "            param_values = param_config.get(\"values\", None)\n",
    "\n",
    "            if param_type == \"cat\":\n",
    "                self.interpretors.append(Variable(param_type,categorical_values=param_values))\n",
    "                \n",
    "            elif param_type == \"bool\":\n",
    "                self.interpretors.append(Variable(param_type))\n",
    "\n",
    "            elif param_type == \"int\":\n",
    "                self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "                \n",
    "            elif param_type == \"real\":\n",
    "                self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "    \n",
    "            \n",
    "    def initial_mean_and_variance(self):\n",
    "        means = []\n",
    "        for inter in self.interpretors:\n",
    "            means = means+inter.get_initial_mean()\n",
    "        \n",
    "        size = len(means)\n",
    "        var = []\n",
    "        for i in range(0,size):\n",
    "            var.append([0.0]*size)\n",
    "            \n",
    "        index = 0\n",
    "        for inter in self.interpretors:\n",
    "            for j in inter.get_initial_variances_diag():\n",
    "                var[index][index] = j\n",
    "                index+=1\n",
    "        return (means,var)\n",
    "    \n",
    "    def convert_for_outside(self,inside_val:np.array): # our regular data as described / inside_val is adequate np.array\n",
    "        ls = list(inside_val)\n",
    "        out = {}\n",
    "        index = 0\n",
    "        for i in range(0,len(self.keys)):\n",
    "            name = self.keys[i]\n",
    "            var = self.interpretors[i]\n",
    "            out[name] = var.parse_outside(ls[index:index+var.get_required_chunck_length()])\n",
    "            index += var.get_required_chunck_length()\n",
    "        # return a dict \n",
    "        return out\n",
    "    \n",
    "    def convert_for_inside(self,outside_val:dict)->np.array: # one hot and normal laws\n",
    "        index = 0\n",
    "        ls = []\n",
    "        for key in self.keys:\n",
    "            variable = self.interpretors[index]\n",
    "            ls = ls + variable.parse_inside(outside_val[key])\n",
    "            index+=1\n",
    "        return np.array(ls)\n",
    "            \n",
    "    \n",
    "class Variable: \n",
    "    def __init__(self,type_v,max_v=0,min_v=0,categorical_values=[]):\n",
    "        self.type = type_v\n",
    "        self.max_v = max_v\n",
    "        self.min_v = min_v\n",
    "        self.categories = list(categorical_values)\n",
    "        \n",
    "    def parse_inside(self,value): # takes element value / convert to Normal law\n",
    "        if self.type==\"cat\":\n",
    "            ls = [0.0]*len(self.categories)\n",
    "            in_v = self.categories.index(value)\n",
    "            ls[in_v] = 1.0\n",
    "            return ls\n",
    "        elif self.type==\"bool\":\n",
    "            if value:\n",
    "                return [1.0]\n",
    "            else:\n",
    "                return [0.0]\n",
    "        else:\n",
    "            return [value]\n",
    "    \n",
    "    def parse_outside(self,values_list): # takes normal vals -> must return values\n",
    "        if self.type==\"cat\":\n",
    "            return self.categories[np.argmax(values_list)]\n",
    "        elif self.type==\"bool\":\n",
    "            return values_list[0]>0.0\n",
    "        elif self.type==\"int\":\n",
    "            val = int(values_list[0]+0.5)\n",
    "            if(val>self.max_v):\n",
    "                return self.max_v\n",
    "            elif val<self.min_v:\n",
    "                return self.min_v\n",
    "            else:\n",
    "                return val\n",
    "        else:\n",
    "            val = values_list[0]\n",
    "            if(val>self.max_v):\n",
    "                return self.max_v\n",
    "            elif val<self.min_v:\n",
    "                return self.min_v\n",
    "            else:\n",
    "                return val\n",
    "    \n",
    "    def get_required_chunck_length(self):\n",
    "        if self.type==\"cat\":\n",
    "            return len(self.categories)\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def get_initial_mean(self):\n",
    "        if self.type == \"cat\":\n",
    "            return [0.0]*len(self.categories)\n",
    "        elif self.type == \"bool\":\n",
    "            return [0.0]\n",
    "        elif self.type == \"int\":\n",
    "            return [(self.min_v+self.max_v)/2]\n",
    "        elif self.type == \"real\":\n",
    "            return [(self.min_v+self.max_v)/2]\n",
    "        \n",
    "    def get_initial_variances_diag(self):\n",
    "        if self.type == \"cat\":\n",
    "            return [1.0]*len(self.categories)\n",
    "        elif self.type == \"bool\":\n",
    "            return [1.0]\n",
    "        elif self.type == \"int\":\n",
    "            return [((-self.min_v+self.max_v)/6)**2]\n",
    "        elif self.type == \"real\":\n",
    "            return [((-self.min_v+self.max_v)/6)**2]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a3a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_config = \\\n",
    "    {'hidden_layer_sizes': {'type': 'int', 'space': 'linear', 'range': (50, 200)},\n",
    "     'alpha': {'type': 'real', 'space': 'log', 'range': (1e-5, 1e1)},\n",
    "     'batch_size': {'type': 'int', 'space': 'linear', 'range': (10, 250)},\n",
    "     'learning_rate_init': {'type': 'real', 'space': 'log', 'range': (1e-5, 1e-1)},\n",
    "     'tol': {'type': 'real', 'space': 'log', 'range': (1e-5, 1e-1)},\n",
    "     'validation_fraction': {'type': 'real', 'space': 'logit', 'range': (0.1, 0.9)},\n",
    "     'beta_1': {'type': 'real', 'space': 'logit', 'range': (0.5, 0.99)},\n",
    "    'beta_7': {'type': 'cat', 'values': [\"v1\",\"v2\",\"v4\"]},\n",
    "     'beta_2': {'type': 'real', 'space': 'logit', 'range': (0.9, 1.0 - 1e-6)},\n",
    "     'epsilon': {'type': 'real', 'space': 'log', 'range': (1e-9, 1e-6)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b03d8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,var = Parser(api_config).initial_mean_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6de9cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125.0,\n",
       " 5.000005,\n",
       " 130.0,\n",
       " 0.050005,\n",
       " 0.050005,\n",
       " 0.5,\n",
       " 0.745,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.9499995,\n",
       " 5.005e-07]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be684385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[62.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 2.5000025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0250025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0250025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3725, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47499975, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5025e-07]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1fe0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Simulator(api_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "027bbee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_layer_sizes': 168,\n",
       "  'alpha': 6.9041255568132405,\n",
       "  'batch_size': 175,\n",
       "  'learning_rate_init': 0.02764418316764335,\n",
       "  'tol': 0.03444696403752804,\n",
       "  'validation_fraction': 0.7868187265162023,\n",
       "  'beta_1': 0.9608349245653117,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.999999,\n",
       "  'epsilon': 5.305244081688534e-07},\n",
       " {'hidden_layer_sizes': 113,\n",
       "  'alpha': 4.825234602940007,\n",
       "  'batch_size': 170,\n",
       "  'learning_rate_init': 0.06087965026702236,\n",
       "  'tol': 0.05433323411349583,\n",
       "  'validation_fraction': 0.6658990346201307,\n",
       "  'beta_1': 0.849185868529297,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.999999,\n",
       "  'epsilon': 7.765958501331991e-07},\n",
       " {'hidden_layer_sizes': 74,\n",
       "  'alpha': 2.0215939576978945,\n",
       "  'batch_size': 53,\n",
       "  'learning_rate_init': 0.03190434627010902,\n",
       "  'tol': 0.0008926242594722647,\n",
       "  'validation_fraction': 0.22000919660008078,\n",
       "  'beta_1': 0.5,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.9,\n",
       "  'epsilon': 4.272527008316972e-07},\n",
       " {'hidden_layer_sizes': 50,\n",
       "  'alpha': 1e-05,\n",
       "  'batch_size': 10,\n",
       "  'learning_rate_init': 1e-05,\n",
       "  'tol': 1e-05,\n",
       "  'validation_fraction': 0.1,\n",
       "  'beta_1': 0.5,\n",
       "  'beta_7': 'v4',\n",
       "  'beta_2': 0.9,\n",
       "  'epsilon': 1e-09},\n",
       " {'hidden_layer_sizes': 64,\n",
       "  'alpha': 0.960617029598613,\n",
       "  'batch_size': 61,\n",
       "  'learning_rate_init': 0.0656247371108643,\n",
       "  'tol': 0.03991004484601134,\n",
       "  'validation_fraction': 0.16983744495758551,\n",
       "  'beta_1': 0.5,\n",
       "  'beta_7': 'v1',\n",
       "  'beta_2': 0.9,\n",
       "  'epsilon': 6.769944169432751e-09},\n",
       " {'hidden_layer_sizes': 196,\n",
       "  'alpha': 7.058110434355367,\n",
       "  'batch_size': 185,\n",
       "  'learning_rate_init': 0.06853533620142478,\n",
       "  'tol': 0.07718114764539524,\n",
       "  'validation_fraction': 0.6893970824807644,\n",
       "  'beta_1': 0.99,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.999999,\n",
       "  'epsilon': 6.856425157454735e-07},\n",
       " {'hidden_layer_sizes': 200,\n",
       "  'alpha': 10.0,\n",
       "  'batch_size': 241,\n",
       "  'learning_rate_init': 0.1,\n",
       "  'tol': 0.1,\n",
       "  'validation_fraction': 0.9,\n",
       "  'beta_1': 0.99,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.999999,\n",
       "  'epsilon': 1e-06},\n",
       " {'hidden_layer_sizes': 55,\n",
       "  'alpha': 4.291009847792613,\n",
       "  'batch_size': 54,\n",
       "  'learning_rate_init': 0.01670108908524036,\n",
       "  'tol': 0.04382613945941629,\n",
       "  'validation_fraction': 0.4451380810841249,\n",
       "  'beta_1': 0.5335661682239933,\n",
       "  'beta_7': 'v2',\n",
       "  'beta_2': 0.9,\n",
       "  'epsilon': 4.539146589752962e-07}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.suggest(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "596114ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.observe(test,list(np.random.rand(len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bff707b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = s.suggest(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6df3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.13771250e+04, 4.60495199e+02, 1.46777500e+04, 5.57738394e+00,\n",
       "        5.53568601e+00, 6.07885717e+01, 7.61918576e+01, 2.37500000e+01,\n",
       "        7.01250000e+01, 1.10000000e+01, 9.94268320e+01, 5.01610281e-05],\n",
       "       [4.60495199e+02, 2.01827899e+01, 5.97951373e+02, 2.21145964e-01,\n",
       "        2.35773393e-01, 2.63032465e+00, 3.22747370e+00, 1.00515461e+00,\n",
       "        3.00353410e+00, 3.78664427e-01, 4.15226829e+00, 2.22551426e-06],\n",
       "       [1.46777500e+04, 5.97951373e+02, 1.99481250e+04, 7.55412313e+00,\n",
       "        7.37861864e+00, 8.16286025e+01, 1.00773480e+02, 3.40000000e+01,\n",
       "        8.58750000e+01, 1.97500000e+01, 1.32349408e+02, 6.86882110e-05],\n",
       "       [5.57738394e+00, 2.21145964e-01, 7.55412313e+00, 3.42133582e-03,\n",
       "        2.87711867e-03, 3.22437015e-02, 3.87005324e-02, 1.74255568e-02,\n",
       "        2.74960919e-02, 8.82741297e-03, 5.05478524e-02, 2.71671731e-08],\n",
       "       [5.53568601e+00, 2.35773393e-01, 7.37861864e+00, 2.87711867e-03,\n",
       "        3.02313247e-03, 3.13842602e-02, 3.89619369e-02, 1.39911916e-02,\n",
       "        3.03607151e-02, 9.08787904e-03, 5.05212846e-02, 2.60910399e-08],\n",
       "       [6.07885717e+01, 2.63032465e+00, 8.16286025e+01, 3.22437015e-02,\n",
       "        3.13842602e-02, 3.61405279e-01, 4.32689650e-01, 1.71473359e-01,\n",
       "        3.62894221e-01, 5.73700384e-02, 5.58667829e-01, 3.04225255e-07],\n",
       "       [7.61918576e+01, 3.22747370e+00, 1.00773480e+02, 3.87005324e-02,\n",
       "        3.89619369e-02, 4.32689650e-01, 5.34339329e-01, 1.75978664e-01,\n",
       "        4.64731364e-01, 8.77880297e-02, 6.89206733e-01, 3.66390219e-07],\n",
       "       [2.37500000e+01, 1.00515461e+00, 3.40000000e+01, 1.74255568e-02,\n",
       "        1.39911916e-02, 1.71473359e-01, 1.75978664e-01, 2.50000000e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.32256065e-01, 9.30675594e-08],\n",
       "       [7.01250000e+01, 3.00353410e+00, 8.58750000e+01, 2.74960919e-02,\n",
       "        3.03607151e-02, 3.62894221e-01, 4.64731364e-01, 0.00000000e+00,\n",
       "        6.25000000e-01, 0.00000000e+00, 5.96655838e-01, 3.36182131e-07],\n",
       "       [1.10000000e+01, 3.78664427e-01, 1.97500000e+01, 8.82741297e-03,\n",
       "        9.08787904e-03, 5.73700384e-02, 8.77880297e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.25000000e-01, 1.17369857e-01, 6.83915702e-08],\n",
       "       [9.94268320e+01, 4.15226829e+00, 1.32349408e+02, 5.05478524e-02,\n",
       "        5.05212846e-02, 5.58667829e-01, 6.89206733e-01, 2.32256065e-01,\n",
       "        5.96655838e-01, 1.17369857e-01, 8.95954933e-01, 4.69177333e-07],\n",
       "       [5.01610281e-05, 2.22551426e-06, 6.86882110e-05, 2.71671731e-08,\n",
       "        2.60910399e-08, 3.04225255e-07, 3.66390219e-07, 9.30675594e-08,\n",
       "        3.36182131e-07, 6.83915702e-08, 4.69177333e-07, 2.83797880e-13]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.var_covar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6f24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4a9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9fd7cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEnthropy:\n",
    "    primary_import = None\n",
    "\n",
    "\n",
    "    class Variable: \n",
    "        def __init__(self,type_v,max_v=0,min_v=0,categorical_values=[]):\n",
    "            self.type = type_v\n",
    "            self.max_v = max_v\n",
    "            self.min_v = min_v\n",
    "            self.categories = list(categorical_values)\n",
    "            \n",
    "        def parse_inside(self,value): # takes element value / convert to Normal law\n",
    "            if self.type==\"cat\":\n",
    "                ls = [0.0]*len(self.categories)\n",
    "                in_v = self.categories.index(value)\n",
    "                ls[in_v] = 1.0\n",
    "                return ls\n",
    "            elif self.type==\"bool\":\n",
    "                if value:\n",
    "                    return [1.0]\n",
    "                else:\n",
    "                    return [0.0]\n",
    "            else:\n",
    "                return [value]\n",
    "        \n",
    "        def parse_outside(self,values_list): # takes normal vals -> must return values\n",
    "            if self.type==\"cat\":\n",
    "                return self.categories[np.argmax(values_list)]\n",
    "            elif self.type==\"bool\":\n",
    "                return values_list[0]>0.0\n",
    "            elif self.type==\"int\":\n",
    "                val = int(values_list[0]+0.5)\n",
    "                if(val>self.max_v):\n",
    "                    return self.max_v\n",
    "                elif val<self.min_v:\n",
    "                    return self.min_v\n",
    "                else:\n",
    "                    return val\n",
    "            else:\n",
    "                val = values_list[0]\n",
    "                if(val>self.max_v):\n",
    "                    return self.max_v\n",
    "                elif val<self.min_v:\n",
    "                    return self.min_v\n",
    "                else:\n",
    "                    return val\n",
    "        \n",
    "        def get_required_chunck_length(self):\n",
    "            if self.type==\"cat\":\n",
    "                return len(self.categories)\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "        def get_initial_mean(self):\n",
    "            if self.type == \"cat\":\n",
    "                return [0.0]*len(self.categories)\n",
    "            elif self.type == \"bool\":\n",
    "                return [0.0]\n",
    "            elif self.type == \"int\":\n",
    "                return [(self.min_v+self.max_v)/2]\n",
    "            elif self.type == \"real\":\n",
    "                return [(self.min_v+self.max_v)/2]\n",
    "            \n",
    "        def get_initial_variances_diag(self):\n",
    "            if self.type == \"cat\":\n",
    "                return [1.0]*len(self.categories)\n",
    "            elif self.type == \"bool\":\n",
    "                return [1.0]\n",
    "            elif self.type == \"int\":\n",
    "                return [((-self.min_v+self.max_v)/6)**2]\n",
    "            elif self.type == \"real\":\n",
    "                return [((-self.min_v+self.max_v)/6)**2]\n",
    "        \n",
    "    class Parser:\n",
    "        def __init__(self,api_config):\n",
    "            self.keys = []\n",
    "            self.interpretors = []\n",
    "            #type_v is one of 'real', 'int', 'cat', 'bool'\n",
    "            for variables in api_config.keys():\n",
    "                self.keys.append(variables)\n",
    "            \n",
    "            for param_name in self.keys:\n",
    "                param_config = api_config[param_name]\n",
    "\n",
    "                param_type = param_config[\"type\"]\n",
    "                param_space = param_config.get(\"space\", None)\n",
    "                param_range = param_config.get(\"range\", None)\n",
    "                param_values = param_config.get(\"values\", None)\n",
    "\n",
    "                if param_type == \"cat\":\n",
    "                    self.interpretors.append(Variable(param_type,categorical_values=param_values))\n",
    "                    \n",
    "                elif param_type == \"bool\":\n",
    "                    self.interpretors.append(Variable(param_type))\n",
    "\n",
    "                elif param_type == \"int\":\n",
    "                    self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "                    \n",
    "                elif param_type == \"real\":\n",
    "                    self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "    \n",
    "            \n",
    "        def initial_mean_and_variance(self):\n",
    "            means = []\n",
    "            for inter in self.interpretors:\n",
    "                means = means+inter.get_initial_mean()\n",
    "            \n",
    "            size = len(means)\n",
    "            var = []\n",
    "            for i in range(0,size):\n",
    "                var.append([0.0]*size)\n",
    "                \n",
    "            index = 0\n",
    "            for inter in self.interpretors:\n",
    "                for j in inter.get_initial_variances_diag():\n",
    "                    var[index][index] = j\n",
    "                    index+=1\n",
    "            return (means,var)\n",
    "        \n",
    "        def convert_for_outside(self,inside_val:np.array): # our regular data as described / inside_val is adequate np.array\n",
    "            ls = list(inside_val)\n",
    "            out = {}\n",
    "            index = 0\n",
    "            for i in range(0,len(self.keys)):\n",
    "                name = self.keys[i]\n",
    "                var = self.interpretors[i]\n",
    "                out[name] = var.parse_outside(ls[index:index+var.get_required_chunck_length()])\n",
    "                index += var.get_required_chunck_length()\n",
    "            # return a dict \n",
    "            return out\n",
    "        \n",
    "        def convert_for_inside(self,outside_val:dict)->np.array: # one hot and normal laws\n",
    "            index = 0\n",
    "            ls = []\n",
    "            for key in self.keys:\n",
    "                variable = self.interpretors[index]\n",
    "                ls = ls + variable.parse_inside(outside_val[key])\n",
    "                index+=1\n",
    "            return np.array(ls)\n",
    "            \n",
    "    \n",
    "    def __init__(self, api_config, **kwargs):\n",
    "        \"\"\"Build wrapper class to use an optimizer in benchmark.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        api_config : dict-like of dict-like\n",
    "            Configuration of the optimization variables. See API description.\n",
    "        \"\"\"\n",
    "        #AbstractOptimizer.__init__(self, api_config)\n",
    "        self.best = [] # {value:eval,vars:{}}\n",
    "        self.parser = Parser(api_config)\n",
    "        mean , var = self.parser.initial_mean_and_variance()\n",
    "        self.mean = np.array(mean)\n",
    "        self.var_covar = np.array(var)\n",
    "\n",
    "        \n",
    "\n",
    "    def suggest(self, n_suggestions=1):\n",
    "        result = []\n",
    "        for i in range(0,n_suggestions):\n",
    "            result.append(self.parser.convert_for_outside(np.random.multivariate_normal(self.mean,self.var_covar)))\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def observe(self, X, y):\n",
    "        \"\"\"Send an observation of a suggestion back to the optimizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of dict-like\n",
    "            Places where the objective function has already been evaluated.\n",
    "            Each suggestion is a dictionary where each key corresponds to a\n",
    "            parameter being optimized.\n",
    "        y : array-like, shape (n,)\n",
    "            Corresponding values where objective has been evaluated\n",
    "        \"\"\"\n",
    "        for xx, yy in zip(X, y):\n",
    "            self.best.append({\"value\":yy,\"indiv\":xx})\n",
    "        self.best = sorted(self.best,key=lambda x:x[\"value\"])\n",
    "        self.best = self.best[0:15]\n",
    "        \n",
    "        if(len(self.best)<4):\n",
    "            # dont update with less than 4 elements \n",
    "            return \n",
    "        \n",
    "        #new matrixn\n",
    "        vectors = [self.parser.convert_for_inside(self.best[0][\"indiv\"])]\n",
    "        new_mean = self.parser.convert_for_inside(self.best[0][\"indiv\"])\n",
    "        for i in range(1,len(self.best)):\n",
    "            tmp = self.parser.convert_for_inside(self.best[i][\"indiv\"])\n",
    "            vectors.append(tmp)\n",
    "            new_mean = new_mean + tmp\n",
    "        new_mean = new_mean / len(self.best)\n",
    "        \n",
    "        new_var = np.zeros((len(new_mean),len(new_mean)))\n",
    "        \n",
    "        for v in vectors:\n",
    "            new_var = new_var + v[np.newaxis].T.dot(v[np.newaxis])\n",
    "        new_var = new_var / len(self.best)\n",
    "        \n",
    "        self.mean = new_mean\n",
    "        self.var_covar = new_var\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f6feca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = CrossEnthropy(api_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92e7f291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_layer_sizes': 154,\n",
       "  'alpha': 4.027773822707006,\n",
       "  'batch_size': 151,\n",
       "  'learning_rate_init': 0.08419608003333348,\n",
       "  'tol': 0.050343451680792406,\n",
       "  'validation_fraction': 0.7282955046572115,\n",
       "  'beta_1': 0.5562836117096867,\n",
       "  'beta_7': 'v4',\n",
       "  'beta_2': 0.9739744948661742,\n",
       "  'epsilon': 5.912202233427976e-07},\n",
       " {'hidden_layer_sizes': 152,\n",
       "  'alpha': 5.401768770893805,\n",
       "  'batch_size': 37,\n",
       "  'learning_rate_init': 0.0857452238835491,\n",
       "  'tol': 0.04869883520230239,\n",
       "  'validation_fraction': 0.48453804943020334,\n",
       "  'beta_1': 0.7109007087959106,\n",
       "  'beta_7': 'v4',\n",
       "  'beta_2': 0.9580907825700273,\n",
       "  'epsilon': 2.5137899819993454e-07}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.suggest(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8463459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cfd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a616eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Variable: \n",
    "    def __init__(self,type_v,max_v=0,min_v=0,categorical_values=[]):\n",
    "        self.type = type_v\n",
    "        self.max_v = max_v\n",
    "        self.min_v = min_v\n",
    "        self.categories = list(categorical_values)\n",
    "        \n",
    "    def parse_inside(self,value): # takes element value / convert to Normal law\n",
    "        if self.type==\"cat\":\n",
    "            ls = [0.0]*len(self.categories)\n",
    "            in_v = self.categories.index(value)\n",
    "            ls[in_v] = 1.0\n",
    "            return ls\n",
    "        elif self.type==\"bool\":\n",
    "            if value:\n",
    "                return [1.0]\n",
    "            else:\n",
    "                return [0.0]\n",
    "        else:\n",
    "            return [value]\n",
    "    \n",
    "    def parse_outside(self,values_list): # takes normal vals -> must return values\n",
    "        if self.type==\"cat\":\n",
    "            return self.categories[np.argmax(values_list)]\n",
    "        elif self.type==\"bool\":\n",
    "            return values_list[0]>0.0\n",
    "        elif self.type==\"int\":\n",
    "            val = int(values_list[0]+0.5)\n",
    "            if(val>self.max_v):\n",
    "                return self.max_v\n",
    "            elif val<self.min_v:\n",
    "                return self.min_v\n",
    "            else:\n",
    "                return val\n",
    "        else:\n",
    "            val = values_list[0]\n",
    "            if(val>self.max_v):\n",
    "                return self.max_v\n",
    "            elif val<self.min_v:\n",
    "                return self.min_v\n",
    "            else:\n",
    "                return val\n",
    "    \n",
    "    def get_required_chunck_length(self):\n",
    "        if self.type==\"cat\":\n",
    "            return len(self.categories)\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def get_initial_mean(self):\n",
    "        if self.type == \"cat\":\n",
    "            return [0.0]*len(self.categories)\n",
    "        elif self.type == \"bool\":\n",
    "            return [0.0]\n",
    "        elif self.type == \"int\":\n",
    "            return [(self.min_v+self.max_v)/2]\n",
    "        elif self.type == \"real\":\n",
    "            return [(self.min_v+self.max_v)/2]\n",
    "        \n",
    "    def get_initial_variances_diag(self):\n",
    "        if self.type == \"cat\":\n",
    "            return [1.0]*len(self.categories)\n",
    "        elif self.type == \"bool\":\n",
    "            return [1.0]\n",
    "        elif self.type == \"int\":\n",
    "            return [((-self.min_v+self.max_v)/6)**2]\n",
    "        elif self.type == \"real\":\n",
    "            return [((-self.min_v+self.max_v)/6)**2]\n",
    "    \n",
    "class Parser:\n",
    "    def __init__(self,api_config):\n",
    "        self.keys = []\n",
    "        self.interpretors = []\n",
    "        #type_v is one of 'real', 'int', 'cat', 'bool'\n",
    "        for variables in api_config.keys():\n",
    "            self.keys.append(variables)\n",
    "        \n",
    "        for param_name in self.keys:\n",
    "            param_config = api_config[param_name]\n",
    "\n",
    "            param_type = param_config[\"type\"]\n",
    "            param_space = param_config.get(\"space\", None)\n",
    "            param_range = param_config.get(\"range\", None)\n",
    "            param_values = param_config.get(\"values\", None)\n",
    "\n",
    "            if param_type == \"cat\":\n",
    "                self.interpretors.append(Variable(param_type,categorical_values=param_values))\n",
    "                \n",
    "            elif param_type == \"bool\":\n",
    "                self.interpretors.append(Variable(param_type))\n",
    "\n",
    "            elif param_type == \"int\":\n",
    "                self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "                \n",
    "            elif param_type == \"real\":\n",
    "                self.interpretors.append(Variable(param_type,max_v=param_range[1],min_v=param_range[0]))\n",
    "\n",
    "        \n",
    "    def initial_mean_and_variance(self):\n",
    "        means = []\n",
    "        for inter in self.interpretors:\n",
    "            means = means+inter.get_initial_mean()\n",
    "        \n",
    "        size = len(means)\n",
    "        var = []\n",
    "        for i in range(0,size):\n",
    "            var.append([0.0]*size)\n",
    "            \n",
    "        index = 0\n",
    "        for inter in self.interpretors:\n",
    "            for j in inter.get_initial_variances_diag():\n",
    "                var[index][index] = j\n",
    "                index+=1\n",
    "        return (means,var)\n",
    "    \n",
    "    def convert_for_outside(self,inside_val:np.array): # our regular data as described / inside_val is adequate np.array\n",
    "        ls = list(inside_val)\n",
    "        out = {}\n",
    "        index = 0\n",
    "        for i in range(0,len(self.keys)):\n",
    "            name = self.keys[i]\n",
    "            var = self.interpretors[i]\n",
    "            out[name] = var.parse_outside(ls[index:index+var.get_required_chunck_length()])\n",
    "            index += var.get_required_chunck_length()\n",
    "        # return a dict \n",
    "        return out\n",
    "    \n",
    "    def convert_for_inside(self,outside_val:dict)->np.array: # one hot and normal laws\n",
    "        index = 0\n",
    "        ls = []\n",
    "        for key in self.keys:\n",
    "            variable = self.interpretors[index]\n",
    "            ls = ls + variable.parse_inside(outside_val[key])\n",
    "            index+=1\n",
    "        return np.array(ls)\n",
    "        \n",
    "\n",
    "class CrossEnthropy:\n",
    "    primary_import = None\n",
    "\n",
    "   \n",
    "    \n",
    "    def __init__(self, api_config, **kwargs):\n",
    "        \"\"\"Build wrapper class to use an optimizer in benchmark.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        api_config : dict-like of dict-like\n",
    "            Configuration of the optimization variables. See API description.\n",
    "        \"\"\"\n",
    "       \n",
    "        self.best = [] # {value:eval,vars:{}}\n",
    "        self.parser = Parser(api_config)\n",
    "        mean , var = self.parser.initial_mean_and_variance()\n",
    "        self.mean = np.array(mean)\n",
    "        self.var_covar = np.array(var)\n",
    "\n",
    "        \n",
    "\n",
    "    def suggest(self, n_suggestions=1):\n",
    "        result = []\n",
    "        for i in range(0,n_suggestions):\n",
    "            result.append(self.parser.convert_for_outside(np.random.multivariate_normal(self.mean,self.var_covar)))\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def observe(self, X, y):\n",
    "        \"\"\"Send an observation of a suggestion back to the optimizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of dict-like\n",
    "            Places where the objective function has already been evaluated.\n",
    "            Each suggestion is a dictionary where each key corresponds to a\n",
    "            parameter being optimized.\n",
    "        y : array-like, shape (n,)\n",
    "            Corresponding values where objective has been evaluated\n",
    "        \"\"\"\n",
    "        for xx, yy in zip(X, y):\n",
    "            self.best.append({\"value\":yy,\"indiv\":xx})\n",
    "        self.best = sorted(self.best,key=lambda x:x[\"value\"])\n",
    "        self.best = self.best[0:15]\n",
    "        \n",
    "        if(len(self.best)<4):\n",
    "            # dont update with less than 4 elements \n",
    "            return \n",
    "        \n",
    "        #new matrixn\n",
    "        vectors = [self.parser.convert_for_inside(self.best[0][\"indiv\"])]\n",
    "        new_mean = self.parser.convert_for_inside(self.best[0][\"indiv\"])\n",
    "        for i in range(1,len(self.best)):\n",
    "            tmp = self.parser.convert_for_inside(self.best[i][\"indiv\"])\n",
    "            vectors.append(tmp)\n",
    "            new_mean = new_mean + tmp\n",
    "        new_mean = new_mean / len(self.best)\n",
    "        \n",
    "        new_var = np.zeros((len(new_mean),len(new_mean)))\n",
    "        \n",
    "        for v in vectors:\n",
    "            new_var = new_var + v[np.newaxis].T.dot(v[np.newaxis])\n",
    "        new_var = new_var / len(self.best)\n",
    "        \n",
    "        self.mean = new_mean\n",
    "        self.var_covar = new_var\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f16337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CrossEnthropy at 0x24473a6ca30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEnthropy({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2a327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
